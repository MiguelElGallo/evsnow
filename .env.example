# ============================================================================
# AZURE EVENT HUB CONFIGURATION
# ============================================================================

# Event Hub Namespace (replace with your actual namespace)
# Format: <namespace-name>.servicebus.windows.net
EVENTHUB_NAMESPACE=eventhub1.servicebus.windows.net

# Topic configurations - map to payload directories
# You can configure multiple topics by incrementing the number (EVENTHUBNAME_2, EVENTHUBNAME_3, etc.)
EVENTHUBNAME_1=topic1
EVENTHUBNAME_1_CONSUMER_GROUP=$Default

# Azure EventHub Connection String (fallback if DefaultAzureCredential fails)
# Get this from Azure Portal → Event Hubs Namespace → Shared access policies
# The pipeline uses DefaultAzureCredential by default (requires `az login`)
AZURE_EVENTHUB_CONNECTION_STRING="Endpoint=sb://eventhub1.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=somekey"
EVENTHUBNAME_1_CONNECTION_STRING="Endpoint=sb://eventhub1.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=somekey"

# ============================================================================
# SNOWFLAKE CONNECTION SETTINGS
# ============================================================================

# Account identifier format: <account_locator>.<region> (e.g., xy12345.us-east-1)
# Find your account identifier: SELECT CURRENT_ACCOUNT() in Snowflake
SNOWFLAKE_ACCOUNT=aaaaaa-bbbbbbb

# Snowflake user with appropriate permissions
SNOWFLAKE_USER=STREAMEV

# RSA Key-Pair Authentication (recommended)
# Generate keys using: ./generate_snowflake_keys.sh
# See SNOWFLAKE_QUICKSTART.md for setup instructions
SNOWFLAKE_PRIVATE_KEY_FILE=/Users/miguelperedo/Github/evsnow/snowflake/rsa_key_encrypted.p8
SNOWFLAKE_PRIVATE_KEY_PASSWORD=nissaN41!

# Snowflake resources
SNOWFLAKE_WAREHOUSE=compute_wh
SNOWFLAKE_DATABASE=INGESTION
SNOWFLAKE_SCHEMA=PUBLIC
SNOWFLAKE_ROLE=STREAM  # Optional - role to use for operations

# ============================================================================
# CONTROL TABLE CONFIGURATION
# ============================================================================

# Control table for checkpointing and watermark management
# The INGESTION_STATUS hybrid table will be created here automatically
TARGET_DB=CONTROL
TARGET_SCHEMA=PUBLIC
TARGET_TABLE=INGESTION_STATUS

# ============================================================================
# SNOWFLAKE INGESTION MAPPING
# ============================================================================

# Snowflake ingestion configuration for EventHub topic1
# Maps EVENTHUBNAME_1 → SNOWFLAKE_1
SNOWFLAKE_1_DATABASE=INGESTION
SNOWFLAKE_1_SCHEMA=PUBLIC
SNOWFLAKE_1_TABLE=events_table
SNOWFLAKE_1_BATCH=100

# Add more mappings as needed:
# EVENTHUBNAME_2=topic2
# EVENTHUBNAME_2_CONSUMER_GROUP=$Default
# SNOWFLAKE_2_DATABASE=INGESTION
# SNOWFLAKE_2_SCHEMA=PUBLIC
# SNOWFLAKE_2_TABLE=other_events_table
# SNOWFLAKE_2_BATCH=100

# ============================================================================
# SNOWFLAKE SNOWPIPE STREAMING CONFIGURATION
# ============================================================================

# PIPE object name (must exist in Snowflake)
# Create using setup_snowpipe_streaming.sql
# The PIPE name typically matches your table name with _PIPE suffix
SNOWFLAKE_PIPE_NAME=EVENTS_TABLE_PIPE

# Schema name for pipe operations
SNOWFLAKE_SCHEMA_NAME=PUBLIC

# ============================================================================
# SMART RETRY CONFIGURATION (OPTIONAL)
# ============================================================================

# Enable LLM-powered intelligent retry decisions
# Analyzes exceptions to determine if operations should be retried
# Use with: uv run python src/main.py run --smart
SMART_RETRY_ENABLED=true

# LLM Provider Configuration
# Supported: openai, azure, anthropic, gemini, groq, cohere
SMART_RETRY_LLM_PROVIDER=azure
SMART_RETRY_LLM_MODEL=gpt-4o-mini  # For Azure: your deployment name

# API Authentication
SMART_RETRY_LLM_API_KEY=KEY

# Azure OpenAI Endpoint (required when provider=azure)
# Format: https://<resource>.cognitiveservices.azure.com/openai/responses?api-version=2025-04-01-preview
SMART_RETRY_LLM_ENDPOINT=https://yourdeployment.cognitiveservices.azure.com/openai/responses?api-version=2025-04-01-preview

# Retry Behavior
SMART_RETRY_MAX_ATTEMPTS=3           # Maximum retry attempts (1-10)
SMART_RETRY_TIMEOUT_SECONDS=10       # LLM request timeout (1-60 seconds)
SMART_RETRY_ENABLE_CACHING=true      # Cache LLM decisions for similar errors

# Example OpenAI Configuration:
# SMART_RETRY_LLM_PROVIDER=openai
# SMART_RETRY_LLM_MODEL=gpt-4o-mini
# SMART_RETRY_LLM_API_KEY=sk-your-api-key-here
# SMART_RETRY_LLM_ENDPOINT=  # Leave empty for OpenAI

# ============================================================================
# LOGFIRE OBSERVABILITY (OPTIONAL)
# ============================================================================

# Enable real-time distributed tracing and observability
# Sign up for free at: https://logfire.pydantic.dev
LOGFIRE_ENABLED=true

# Logfire API Token (required when send_to_logfire=true)
# Get your token from Logfire dashboard
LOGFIRE_TOKEN=your_key_logfire

# Service Configuration
LOGFIRE_SERVICE_NAME=your_service_name
LOGFIRE_ENVIRONMENT=development

# Output Configuration
# Send traces to Logfire cloud (requires token)
LOGFIRE_SEND_TO_LOGFIRE=true
# Enable Rich console output with traces
LOGFIRE_CONSOLE_LOGGING=true

# Log Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOGFIRE_LOG_LEVEL=INFO

# Example Production Configuration:
# LOGFIRE_ENABLED=true
# LOGFIRE_TOKEN=pylf_v1_us_your-production-token
# LOGFIRE_SERVICE_NAME=evsnow-prod
# LOGFIRE_ENVIRONMENT=production
# LOGFIRE_SEND_TO_LOGFIRE=true
# LOGFIRE_CONSOLE_LOGGING=false
# LOGFIRE_LOG_LEVEL=WARNING
